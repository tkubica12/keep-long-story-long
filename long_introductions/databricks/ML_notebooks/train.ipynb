{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53b85a66-06da-4021-b3fb-6676268d5873",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c13a887c-85c4-49ec-a14a-4681f87b7841",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load cleaned data from Feature Store into DataFrame\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "fs = FeatureStoreClient()\n",
    "df = fs.read_table(name='main.default.user_financial_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "157bf269-86e9-4bbf-b2c9-e004e5a6c590",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 300327\n",
      "Test count: 75061\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "print(f\"Train count: {train_df.count()}\")\n",
    "print(f\"Test count: {test_df.count()}\")\n",
    "\n",
    "# Store test set for later use\n",
    "test_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.default.lending_club_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "296cb453-d78c-47ec-9927-c3be541faddc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop user_id, not a feature\n",
    "train_df = train_df.drop(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94311f33-4876-4140-8554-e07261ca0e07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "# Get columns of type string\n",
    "categorical_cols = [field for (field, dataType) in train_df.dtypes if dataType == \"string\"]\n",
    "\n",
    "# Create name for categorical columns - one for index, one for OHE\n",
    "index_output_cols = [x + \"Index\" for x in categorical_cols]\n",
    "ohe_output_cols = [x + \"OHE\" for x in categorical_cols]\n",
    "\n",
    "# Assign index to each category\n",
    "string_indexer = StringIndexer(inputCols=categorical_cols, outputCols=index_output_cols, handleInvalid=\"skip\")\n",
    "\n",
    "# Convert category index to binary vector (dummy variables)\n",
    "ohe_encoder = OneHotEncoder(inputCols=index_output_cols, outputCols=ohe_output_cols)\n",
    "\n",
    "# Create vector of features (numerical + categorical)\n",
    "numeric_cols = [field for (field, dataType) in train_df.dtypes if (dataType in [\"int\", \"double\"])]\n",
    "assembler_inputs = ohe_output_cols + numeric_cols\n",
    "vec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bd2df05-3479-4fec-a132-07beca4950d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/14 18:31:52 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5d3b3ee9f54976b8ab268f68f05dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/14 18:31:54 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b258e5b300564c5b803570b6a32a9fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run ID: 65a6460acd1c41cfbaec59d03b808e15\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "experiment_name = \"/Shared/lending_club/\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "# Start a new MLflow run\n",
    "with mlflow.start_run(run_name=\"Logistic Regression\") as run:\n",
    "    \n",
    "    # Define model\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=\"loan_status\")\n",
    "\n",
    "    # Define pipeline\n",
    "    pipeline = Pipeline(stages=[string_indexer, ohe_encoder, vec_assembler, lr])\n",
    "\n",
    "    # Train model\n",
    "    model = pipeline.fit(train_df)\n",
    "\n",
    "    # Apply the pipeline model to the test dataset.\n",
    "    pred_df = model.transform(test_df)\n",
    "\n",
    "    # Evaluate model\n",
    "    multiclass_evaluator = MulticlassClassificationEvaluator(labelCol=\"loan_status\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    f1_score = multiclass_evaluator.evaluate(pred_df)\n",
    "\n",
    "    multiclass_evaluator.setMetricName(\"accuracy\")\n",
    "    accuracy = multiclass_evaluator.evaluate(pred_df)\n",
    "\n",
    "    # Log model metrics\n",
    "    mlflow.log_metric(\"F1 Score\", f1_score)\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "\n",
    "    # Create model signature and log model\n",
    "    from mlflow.models import infer_signature\n",
    "    signature = infer_signature(test_df.drop(\"loan_status\"), pred_df.select(\"prediction\"))\n",
    "    mlflow.spark.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "    print(f\"Current run ID: {mlflow.active_run().info.run_id}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
